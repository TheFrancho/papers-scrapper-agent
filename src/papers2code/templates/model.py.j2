import torch
import torch.nn as nn

# Paper citations:
# {% for c in citations[:3] %}
# - {{ c.section }}: "{{ c.quote }}"
# {% endfor %}

# Model config from Methods:
# depth={{ model.depth }}, widen_factor={{ model.widen_factor }}, dropout={{ model.dropout }}

class BasicBlock(nn.Module):
    def __init__(self, in_ch, out_ch, stride=1, drop=0.0):
        super().__init__()
        self.equalInOut = in_ch == out_ch and stride == 1
        self.bn1 = nn.BatchNorm2d(in_ch)
        self.conv1 = nn.Conv2d(in_ch, out_ch, 3, stride=stride, padding=1, bias=False)
        self.bn2 = nn.BatchNorm2d(out_ch)
        self.conv2 = nn.Conv2d(out_ch, out_ch, 3, padding=1, bias=False)
        self.shortcut = (nn.Identity() if self.equalInOut
                         else nn.Conv2d(in_ch, out_ch, 1, stride=stride, bias=False))
        self.dropout = nn.Dropout(p={{ model.dropout }})

    def forward(self, x):
        out = self.conv1(torch.relu(self.bn1(x)))
        out = self.conv2(self.dropout(torch.relu(self.bn2(out))))
        out += self.shortcut(x)
        return out

def _make_wide_layer(in_ch, k, n, stride, drop):
    layers = []
    ch = in_ch * k
    for i in range(n):
        layers.append(BasicBlock(in_ch if i==0 else ch, ch, stride if i==0 else 1, drop))
    return nn.Sequential(*layers), ch

class WideResNet(nn.Module):
    def __init__(self, depth={{ model.depth }}, widen_factor={{ model.widen_factor }}, num_classes={{ dataset.num_classes }}, drop={{ model.dropout }}):
        super().__init__()
        # WRN expects depth = 6n + 4 [paper]
        assert (depth - 4) % 6 == 0, "WRN depth must be 6n+4"
        n = (depth - 4) // 6
        k = widen_factor

        self.conv1 = nn.Conv2d(3, 16, 3, padding=1, bias=False)
        self.block1, ch1 = _make_wide_layer(16, k, n, 1, drop)
        self.block2, ch2 = _make_wide_layer(32, k, n, 2, drop)
        self.block3, ch3 = _make_wide_layer(64, k, n, 2, drop)
        self.bn = nn.BatchNorm2d(64*k)
        self.fc = nn.Linear(64*k, num_classes)

    def forward(self, x):
        out = self.conv1(x)
        out = self.block1(out)
        out = self.block2(out)
        out = self.block3(out)
        out = torch.relu(self.bn(out))
        out = torch.nn.functional.adaptive_avg_pool2d(out, 1).flatten(1)
        out = self.fc(out)
        return out

def build_model() -> nn.Module:
    return WideResNet()
